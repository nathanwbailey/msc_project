{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8207d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import decomposition\n",
    "import seaborn as sns\n",
    "import random\n",
    "from random import randint\n",
    "from augment_functions import random_mask, resize_encoder\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional.image.ssim import (\n",
    "    structural_similarity_index_measure,\n",
    ")\n",
    "from torchmetrics.functional.image.psnr import peak_signal_noise_ratio\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from downstream_model_lstm_no_decoder.downstream_task_main import (\n",
    "    downstream_task as downstream_task_lstm_no_decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd59ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d7360fe3fb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb32bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_encoder(sample):\n",
    "    sample = F.interpolate(\n",
    "        sample, size=(144, 72), mode=\"bicubic\", align_corners=False\n",
    "    )\n",
    "    return sample\n",
    "\n",
    "\n",
    "def random_mask(sample, mask_prob_low=0.7, mask_prob_high=0.7):\n",
    "    if mask_prob_low == mask_prob_high:\n",
    "        mask_prob = mask_prob_low\n",
    "    else:\n",
    "        mask_prob = random.uniform(mask_prob_low, mask_prob_high)\n",
    "    random_tensor = torch.rand(sample.shape, device=sample.device)\n",
    "    mask = (random_tensor > mask_prob).float()\n",
    "    masked_image = sample * mask\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "class WeatherBenchDatasetWindow(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        context_length,\n",
    "        target_length,\n",
    "        stride=1,\n",
    "        mask_prob_low=0.7,\n",
    "        mask_prob_high=0.7,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.context_length = context_length\n",
    "        self.target_length = target_length\n",
    "        self.stride = stride\n",
    "        self.mask_prob_low = mask_prob_low\n",
    "        self.mask_prob_high = mask_prob_high\n",
    "\n",
    "    def __len__(self):\n",
    "        return (\n",
    "            self.data.shape[0] - (self.context_length + self.target_length)\n",
    "        ) // self.stride + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = random_mask(\n",
    "            resize_encoder(self.data[idx : idx + self.context_length]),\n",
    "            mask_prob_low=self.mask_prob_low,\n",
    "            mask_prob_high=self.mask_prob_high,\n",
    "        )\n",
    "        y = self.data[\n",
    "            idx\n",
    "            + self.context_length : idx\n",
    "            + self.context_length\n",
    "            + self.target_length\n",
    "        ]\n",
    "        y_masked = random_mask(\n",
    "            resize_encoder(y),\n",
    "            mask_prob_low=self.mask_prob_low,\n",
    "            mask_prob_high=self.mask_prob_high,\n",
    "        )\n",
    "        return x, y_masked, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7adb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = torch.load(\n",
    "    \"downstream_model_no_decoder_weight_decay.pth\",\n",
    "    weights_only=False,\n",
    "    map_location=DEVICE,\n",
    ")\n",
    "model = torch.load(\n",
    "    \"simclr_decoder_freeze.pth\", weights_only=False, map_location=DEVICE\n",
    ")\n",
    "model.eval()\n",
    "seq2seq_model.eval()\n",
    "\n",
    "OUTPUT_LEN = 20\n",
    "\n",
    "seq2seq_model.output_len = OUTPUT_LEN\n",
    "\n",
    "encoder_model = model.model.encoder\n",
    "decoder_model = model.decoder\n",
    "\n",
    "data = torch.load(\"/vol/bitbucket/nb324/ERA5_64x32_daily_850.pt\")\n",
    "n_samples = data.shape[0]\n",
    "n_train = int(n_samples * 0.6)\n",
    "n_valid = int(n_samples * 0.2)\n",
    "data = data[n_train + n_valid :]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "n_samples = data.shape[0]\n",
    "\n",
    "n_train = int(n_samples * 0.6)\n",
    "n_valid = int(n_samples * 0.2)\n",
    "\n",
    "train_data = data[:n_train]\n",
    "valid_data = data[n_train : n_train + n_valid]\n",
    "test_data = data[n_train + n_valid :]\n",
    "\n",
    "mean = train_data.mean(dim=(0, 2, 3), keepdim=True)\n",
    "std = train_data.std(dim=(0, 2, 3), keepdim=True)\n",
    "\n",
    "test_data = (test_data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b79fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(input_data, output_data, encoder_model):\n",
    "    B, T, C, H, W = input_data.shape\n",
    "    input_data = input_data.reshape(B * T, C, H, W)\n",
    "    input_encoded_data, _ = encoder_model(input_data)\n",
    "\n",
    "    input_encoded_data = input_encoded_data.reshape(B, T, -1)\n",
    "    B, T, C, H, W = output_data.shape\n",
    "    output_data = output_data.reshape(B * T, C, H, W)\n",
    "\n",
    "    output_encoded_data = encoder_model(output_data)[0]\n",
    "    output_encoded_data = output_encoded_data.reshape(B, T, -1)\n",
    "    return input_encoded_data, output_encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1a8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(\n",
    "    testloader,\n",
    "    encoder_model,\n",
    "    seq2seq_model,\n",
    "    decoder_model,\n",
    "    std,\n",
    "    mean,\n",
    "    train_data,\n",
    "    teacher_forcing=False,\n",
    "):\n",
    "    mse_loss = torch.nn.MSELoss(reduction=\"none\")\n",
    "    mse = []\n",
    "    ssim = []\n",
    "    psnr = []\n",
    "    for batch in testloader:\n",
    "        with torch.no_grad():\n",
    "            input_data = batch[0].to(DEVICE)\n",
    "            output_data_masked = batch[1].to(DEVICE)\n",
    "            output_data = batch[2].to(DEVICE)\n",
    "            input_encoded_data, output_encoded_data = prepare_inputs(\n",
    "                input_data, output_data_masked, encoder_model\n",
    "            )\n",
    "            if teacher_forcing:\n",
    "                model_pred = seq2seq_model(\n",
    "                    input_encoded_data, output_encoded_data, eps=1.0\n",
    "                )\n",
    "            else:\n",
    "                model_pred = seq2seq_model(input_encoded_data)\n",
    "            if model_pred.ndim == 2:\n",
    "                model_pred = model_pred.unsqueeze(0)\n",
    "            B, T, L = model_pred.shape\n",
    "            model_pred = model_pred.reshape(B * T, L)\n",
    "            output_encoded_data = output_encoded_data.reshape(B * T, L)\n",
    "            decoded_data = decoder_model(model_pred)\n",
    "            B, T, C, H, W = output_data.shape\n",
    "            decoded_data = decoded_data.reshape(B, T, C, H, W)\n",
    "\n",
    "            mse_l = mse_loss(decoded_data, output_data)\n",
    "            mse_l = mse_l.mean(dim=(0, 2, 3, 4)).cpu().numpy()\n",
    "\n",
    "            decoded_data_ = decoded_data.reshape(B * T, C, H, W)\n",
    "            output_data_ = output_data.reshape(B * T, C, H, W)\n",
    "            decoded_data_ = decoded_data_ * std + mean\n",
    "            output_data_ = output_data_ * std + mean\n",
    "\n",
    "            x_min = train_data.amin(dim=(0, 2, 3), keepdim=True)\n",
    "            x_max = train_data.amax(dim=(0, 2, 3), keepdim=True)\n",
    "\n",
    "            decoded_data_ = (decoded_data_ - x_min) / (x_max - x_min + 1e-8)\n",
    "            output_data_ = (output_data_ - x_min) / (x_max - x_min + 1e-8)\n",
    "\n",
    "            ssim_l = structural_similarity_index_measure(\n",
    "                decoded_data_, output_data_, data_range=1.0, reduction=None\n",
    "            )\n",
    "            psnr_l = peak_signal_noise_ratio(\n",
    "                decoded_data_,\n",
    "                output_data_,\n",
    "                reduction=None,\n",
    "                data_range=1.0,\n",
    "                dim=[1, 2, 3],\n",
    "            )\n",
    "\n",
    "            ssim_l = ssim_l.reshape(B, T).mean(0).cpu().numpy()\n",
    "            psnr_l = psnr_l.reshape(B, T).mean(0).cpu().numpy()\n",
    "\n",
    "            mse.append(mse_l)\n",
    "            ssim.append(ssim_l)\n",
    "            psnr.append(psnr_l)\n",
    "\n",
    "    print(f\"MSE Loss: {np.mean(mse, axis=0)}\")\n",
    "    print(f\"Masked Normalised SSIM Loss: {np.mean(ssim, axis=0)}\")\n",
    "    print(f\"Masked Normalised PSNR Loss: {np.mean(psnr, axis=0)}\")\n",
    "    mse_time = np.mean(mse, axis=0)\n",
    "    ssim_time = np.mean(ssim, axis=0)\n",
    "    psnr_time = np.mean(psnr, axis=0)\n",
    "    mse_thresh = 1.2 * mse_time[0]\n",
    "    ssim_thresh = 0.8 * ssim_time[0]\n",
    "    psnr_thresh = 0.8 * psnr_time[0]\n",
    "    timesteps = np.arange(len(mse_time))\n",
    "    print(timesteps)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "    axes[0].plot(timesteps, mse_time, label=\"MSE\", color=\"blue\")\n",
    "    axes[0].axhline(\n",
    "        y=mse_thresh,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"20% above starting value\",\n",
    "    )\n",
    "    axes[0].set_ylabel(\"MSE\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(timesteps, ssim_time, label=\"SSIM\", color=\"green\")\n",
    "    axes[1].axhline(\n",
    "        y=ssim_thresh,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"20% below starting value\",\n",
    "    )\n",
    "    axes[1].set_ylabel(\"SSIM\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(timesteps, psnr_time, label=\"PSNR\", color=\"orange\")\n",
    "    axes[2].axhline(\n",
    "        y=psnr_thresh,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"20% below starting value\",\n",
    "    )\n",
    "    axes[2].set_ylabel(\"PSNR\")\n",
    "    axes[2].set_xlabel(\"Time step\")\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xticks(timesteps)\n",
    "\n",
    "    mse_cross = np.argmax(mse_time > mse_thresh)\n",
    "    ssim_cross = np.argmax(ssim_time < ssim_thresh)\n",
    "    psnr_cross = np.argmax(psnr_time < psnr_thresh)\n",
    "    axes[0].axvline(\n",
    "        x=mse_cross, color=\"purple\", linestyle=\":\", label=\"Threshold crossed\"\n",
    "    )\n",
    "    axes[1].axvline(\n",
    "        x=ssim_cross, color=\"purple\", linestyle=\":\", label=\"Threshold crossed\"\n",
    "    )\n",
    "    axes[2].axvline(\n",
    "        x=psnr_cross, color=\"purple\", linestyle=\":\", label=\"Threshold crossed\"\n",
    "    )\n",
    "\n",
    "    plt.suptitle(\"Metrics Over Time with 20% Threshold Lines\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9a819",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_dataset = WeatherBenchDatasetWindow(\n",
    "    data=test_data,\n",
    "    context_length=30,\n",
    "    target_length=OUTPUT_LEN,\n",
    "    stride=1,\n",
    "    mask_prob_low=0.7,\n",
    "    mask_prob_high=0.7,\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error(\n",
    "    testloader,\n",
    "    encoder_model,\n",
    "    seq2seq_model,\n",
    "    decoder_model,\n",
    "    std,\n",
    "    mean,\n",
    "    train_data,\n",
    "    teacher_forcing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1326525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_error(testloader, encoder_model, seq2seq_model, decoder_model, std, mean, train_data, teacher_forcing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
